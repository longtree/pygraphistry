{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphistry\n",
    "import pandas as pd\n",
    "\n",
    "from ml.dgl_utils import *\n",
    "from ml.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig()\n",
    "logger = logging.getLogger('demo')\n",
    "logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphistry.register(api=3, protocol=\"https\", server=\"hub.graphistry.com\", username=\"..\", password=\"..\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We import a subgraph from the LittleSis dataset centered around BlackRock, Inc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edf = pd.read_csv('data/edges_blackrock.csv', index_col=0)\n",
    "ndf = pd.read_csv('data/nodes_blackrock.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore subgraphs\n",
    "`get_graphistry_from_search` is a useful way to do fuzzy search over the dataframes to retrieve useful information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = get_graphistry_from_search('Bank', 'to_node', 'from_node', 'Node', edf, ndf)\n",
    "g.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = get_graphistry_from_search('climate', 'to_node', 'from_node', 'Node', edf, ndf)\n",
    "g.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore Milieu\n",
    "`get_graphistry_from_milieu_search` is a useful way to do fuzzy search over the dataframes to retrieve useful information over 1 and 2 connections from `search_term`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this works much better on full LittleSis data, than just the small BlackRock sample above...\n",
    "g = get_graphistry_from_milieu_search('meta', 'to_node', 'from_node', 'Node', edf, ndf, both=True)\n",
    "g.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's encode the graph as a DGL graph for use in Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's explicitly make a node level target (simplified to two classes)\n",
    "node_target = ndf.Types.apply(lambda x: x.split(',')[0])\n",
    "node_target = pd.DataFrame({'Types': node_target.values}, index=node_target.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(node_target.Types)  # we have a simple target defined here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndf.columns # not all of these are useful for building a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndf.info() # and we can see that few are present past the 5th entry below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_cols = ['Node', 'Blurb', 'Summary'] # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nndf = ndf[good_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "src, dst = 'from_node', 'to_node' #backwards due to the way we scraped the data\n",
    "node_column = 'Node'\n",
    "#node_target = 'Types' # uncomment to build node_target above\n",
    "edge_target = 'relationship_type' # can be column label or, as in previous cell, the df itself.\n",
    "\n",
    "# can use ndf instead of nndf here, no problem, doesn't really change analysis\n",
    "graph = BaseDGLGraphFromPandas(nndf, edf, src, dst, node_column, node_target=node_target, edge_target=edge_target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.build_simple_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "graph.embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we have a DGL graph with ndata and edata built via dirty_cat\n",
    "graph.graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now we with this in hand, we can train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml.networks import GCN  # this under the hood, only works for ndata\n",
    "# this `logits = model(g, features)` breaks it if we switch to edata in training call. \n",
    "# TODO: understand why GCN is breaking this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the DGL graph object\n",
    "g = graph.graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have to add masks (i know these are not exclusive, but this is fast and torchie, for demonstration only)\n",
    "g.ndata['train_mask'] = torch.zeros(g.ndata['feature'].shape[0], dtype=torch.bool).bernoulli(0.7)\n",
    "g.ndata['test_mask'] = torch.zeros(g.ndata['feature'].shape[0], dtype=torch.bool).bernoulli(0.2)\n",
    "g.ndata['val_mask'] = torch.zeros(g.ndata['feature'].shape[0], dtype=torch.bool).bernoulli(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.ndata['train_mask'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_node_model(g, model, n_epochs=100):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "    best_val_acc = 0\n",
    "    best_test_acc = 0\n",
    "\n",
    "    features = g.ndata['feature']\n",
    "    labels = g.ndata['target']\n",
    "    targets = labels.argmax(1) # a bit of a hack\n",
    "    train_mask = g.ndata['train_mask']\n",
    "    val_mask = g.ndata['val_mask']\n",
    "    test_mask = g.ndata['test_mask']\n",
    "    for e in range(n_epochs):\n",
    "        # Forward\n",
    "        logits = model(g, features.float())\n",
    "\n",
    "        # Compute prediction\n",
    "        pred = logits.argmax(1)\n",
    "\n",
    "        # Compute loss\n",
    "        # Note that you should only compute the losses of the nodes in the training set.\n",
    "        loss = F.cross_entropy(logits[train_mask], labels[train_mask])\n",
    "\n",
    "        # Compute accuracy on training/validation/test\n",
    "        train_acc = (pred[train_mask] == targets[train_mask]).float().mean()\n",
    "        val_acc = (pred[val_mask] == targets[val_mask]).float().mean()\n",
    "        test_acc = (pred[test_mask] == targets[test_mask]).float().mean()\n",
    "\n",
    "        # Save the best validation accuracy and the corresponding test accuracy.\n",
    "        if best_val_acc < val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_test_acc = test_acc\n",
    "\n",
    "        # Backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if e % 20 == 0:\n",
    "            print('In epoch {}, loss: {:.3f}, val acc: {:.3f} (best {:.3f}), test acc: {:.3f} (best {:.3f})'.format(\n",
    "                e, loss, val_acc, best_val_acc, test_acc, best_test_acc))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to get a sense of the different parts in training loop above\n",
    "features = g.ndata['feature']\n",
    "labels = g.ndata['target']\n",
    "train_mask = g.ndata['train_mask']\n",
    "val_mask = g.ndata['val_mask']\n",
    "test_mask = g.ndata['test_mask']\n",
    "targets = labels.argmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.shape, labels.shape, targets.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = g.ndata['feature'].shape[1]\n",
    "latent_dim = 32\n",
    "num_classes = g.ndata['target'].shape[1]\n",
    "\n",
    "# here is the model\n",
    "model = GCN(num_features, latent_dim, num_classes)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = model(g, features.float()) # have to call .float, or it gives a type(DOUBLE) error.\n",
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# untrained comparison\n",
    "pred = logits.argmax(1)\n",
    "sum(pred == targets)/len(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_node_model(g, model, 221)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trained comparison\n",
    "logits = model(g, features.float())\n",
    "pred = logits.argmax(1)\n",
    "# really shitty accuracy\n",
    "sum(pred == targets)/len(pred) # only 8% better than random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get forward activations \n",
    "activation = {}\n",
    "def get_activation(name):\n",
    "    def hook(model, input, output):\n",
    "        activation[name] = output.detach()\n",
    "    return hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.conv1.register_forward_hook(get_activation('conv1'))\n",
    "model.conv2.register_forward_hook(get_activation('conv2'))\n",
    "# now call model to do forward  \n",
    "logits = model(g, features.float())\n",
    "# this will load the dictionary\n",
    "print(activation['conv1'])\n",
    "print(activation['conv2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just a pretty graph\n",
    "plt.figure(); plt.imshow(np.cov(activation['conv1']>0), aspect='auto',  cmap=plt.get_cmap('plasma'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's UMAP it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.umap(show=True, color_labels=activation['conv2'].argmax(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ux = graph._embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndf['x'] = ux.T[0]*100\n",
    "ndf['y'] = ux.T[1]*100\n",
    "# hmmm not working...\n",
    "gr = graphistry.edges(edf, 'to_node', 'from_node').nodes(ndf, 'Node').bind(point_x='x', point_y='y')\n",
    "gr.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
